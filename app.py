import streamlit as st
import os
import shutil

# --- å»¶è¿Ÿå¯¼å…¥æ ¸å¿ƒæ¨¡å— ---
# æˆ‘ä»¬ä¸åœ¨è¿™é‡Œ import core.xxxï¼Œé˜²æ­¢å¯åŠ¨å¡é¡¿
# from core.data_processor import process_pdf_to_training_data
# from core.trainer import train_user_model
# from core.rag_engine import RAGEngine

# åˆå§‹åŒ–è·¯å¾„
UPLOAD_DIR = "data/uploads"
DATA_DIR = "data/processed"
MODEL_DIR = "models/user_adapters"

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

st.set_page_config(page_title="DeepRAG Customizer", layout="wide")
st.title("ğŸ§  DeepRAG: æ‰“é€ ä½ çš„ä¸“å±å‚ç›´é¢†åŸŸæ¨¡å‹")

# --- ä¾§è¾¹æ ï¼šä¸Šä¼ ä¸å¾®è°ƒ ---
with st.sidebar:
    st.header("1. ä¸Šä¼ ç§æœ‰æ–‡æ¡£")
    uploaded_file = st.file_uploader("ä¸Šä¼  PDF èµ„æ–™", type=["pdf"])
    
    if uploaded_file:
        file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success(f"å·²ä¿å­˜: {uploaded_file.name}")
        
        st.header("2. å¼€å§‹å¾®è°ƒ")
        if st.button("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–å¾®è°ƒ"):
            # --- å…³é”®ä¿®æ”¹ï¼šåœ¨è¿™é‡Œæ‰ Import ---
            with st.spinner("æ­£åœ¨åŠ è½½ AI æ ¸å¿ƒå¼•æ“ (é¦–æ¬¡è¿è¡Œè¾ƒæ…¢)..."):
                from core.data_processor import process_pdf_to_training_data
                from core.trainer import train_user_model
                
            with st.status("æ­£åœ¨è¿›è¡Œè‡ªåŠ¨åŒ–å¾®è°ƒ...", expanded=True) as status:
                st.write("âš™ï¸ æ­£åœ¨è§£æ PDF å¹¶ç”Ÿæˆè®­ç»ƒæ•°æ®...")
                json_path = os.path.join(DATA_DIR, "train.json")
                count = process_pdf_to_training_data(file_path, json_path)
                st.write(f"âœ… ç”Ÿæˆäº† {count} æ¡è®­ç»ƒæ ·æœ¬ã€‚")
                
                st.write("ğŸ‹ï¸â€â™‚ï¸ æ­£åœ¨è°ƒç”¨ GPU è¿›è¡Œ LoRA å¾®è°ƒ...")
                adapter_name = uploaded_file.name.split('.')[0]
                output_path = os.path.join(MODEL_DIR, adapter_name)
                
                if os.path.exists(output_path):
                    shutil.rmtree(output_path)
                    
                train_user_model(json_path, output_path)
                st.write("âœ… å¾®è°ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜ã€‚")
                
                st.session_state["current_adapter"] = output_path
                st.session_state["current_pdf"] = file_path
                status.update(label="å¾®è°ƒæµç¨‹ç»“æŸï¼", state="complete", expanded=False)

# --- ä¸»ç•Œé¢ï¼šé—®ç­” ---
st.header("3. æ™ºèƒ½é—®ç­” (RAG + Fine-tuned)")

if "current_adapter" in st.session_state:
    adapter_path = st.session_state["current_adapter"]
    pdf_path = st.session_state["current_pdf"]
    
    st.info(f"å½“å‰ä½¿ç”¨çš„å¾®è°ƒæ¨¡å‹: {os.path.basename(adapter_path)}")
    
    # è¿™é‡Œçš„ Import ä¹Ÿæ”¾åˆ°å‡½æ•°é‡Œ
    @st.cache_resource
    def get_engine(adapter_path, pdf_path):
        from core.rag_engine import RAGEngine # å»¶è¿Ÿå¯¼å…¥
        engine = RAGEngine()
        engine.load_model(adapter_path)
        engine.build_index(pdf_path)
        return engine
        
    engine = get_engine(adapter_path, pdf_path)
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if prompt := st.chat_input("å‘ä½ çš„ä¸“å±æ¨¡å‹æé—®..."):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("assistant"):
            with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
                response = engine.chat(prompt)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
else:
    st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF å¹¶å®Œæˆå¾®è°ƒã€‚")